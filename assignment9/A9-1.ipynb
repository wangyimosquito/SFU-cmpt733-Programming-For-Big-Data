{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Hypothesis Testing (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we cannot get the full population but only a sample. If we derive an interesting result from a sample, how likely can we derive the same result from the entire population? In other words, we want to know whether this result is a true finding or it just happens in the sample by chance. Hypothesis testing aims to answer this fundamental question. \n",
    "\n",
    "\n",
    "**Hypothesis Testing**\n",
    "1. Why A/B testing?  \n",
    "2. What is a permutation test? How to implement it?\n",
    "3. What is p-value? How to avoid p-hacking? \n",
    "4. What is a chi-squared test? How to implement it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. A/B Testing\n",
    "> Acknowledgment: Thank [Greg Baker](http://www.cs.sfu.ca/~ggbaker/) for helping me to prepare this task.\n",
    "\n",
    "A very common technique to evaluate changes in a user interface is A/B testing: show some users interface A, some interface B, and then look to see if one performs better than the other.\n",
    "\n",
    "Suppose I started an A/B test on CourSys. Here are the two interfaces that I want to compare with. I want to know whether a good placeholder in the search box can attract more users to use the `search` feature.\n",
    "\n",
    "\n",
    "![](img/ab-testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided [searchlog.json](searchlog.json) has information about users' usage. The question I was interested in: is the number of searches per user different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to first pick up a **test statistic** to quantify how good an interface is. Here, we choose \"the search_count mean\". \n",
    "\n",
    "Please write the code to compute **the difference of the search_count means between interface A and Interface B.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the difference of the search_count means between interface A and B is : -0.13500569535052287\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_ui</th>\n",
       "      <th>search_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.663793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.798799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_ui  search_count\n",
       "0         A      0.663793\n",
       "1         B      0.798799"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df  = pd.read_json('searchlog.json', lines=True)\n",
    "\n",
    "mean = df[['search_ui','search_count']].groupby('search_ui',as_index=False).mean()\n",
    "\n",
    "\n",
    "\n",
    "mean_A = mean['search_count'].iloc[0]\n",
    "mean_B = mean['search_count'].iloc[1]\n",
    "\n",
    "diff = mean_A-mean_B\n",
    "\n",
    "print('the difference of the search_count means between interface A and B is :', diff)\n",
    "mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we find that the mean value increased by 0.135. Then, we wonder whether this result is just caused by random variation. \n",
    "\n",
    "We define the Null Hypothesis as\n",
    " * The difference in search_count mean between Interface A and Interface B is caused by random variation. \n",
    " \n",
    "Then the next job is to check whether we can reject the null hypothesis or not. If it does, we can adopt the alternative explanation:\n",
    " * The difference in search_count mean  between Interface A and Interface B is caused by the design differences between the two.\n",
    "\n",
    "We compute the p-value of the observed result. If p-value is low (e.g., <0.01), we can reject the null hypothesis, and adopt  the alternative explanation.  \n",
    "\n",
    "Please implement a permutation test (numSamples = 10000) to compute the p-value. Note that you are NOT allowed to use an implementation in an existing library. You have to implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value =  0.1263\n",
      "The difference is caused by design difference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ITER = 10000\n",
    "THRESHOULD = 0.135\n",
    "cnt = 0\n",
    "\n",
    "ori_count = df['search_count'].to_numpy()\n",
    "\n",
    "for i in range(ITER):\n",
    "\t#permutation\n",
    "\tnp.random.shuffle(ori_count)\n",
    "\tdf['search_count'] =  ori_count.tolist()\n",
    "\tmean = df[['search_ui','search_count']].groupby('search_ui',as_index=False).mean()\n",
    "\tmean_A = mean['search_count'].iloc[0]\n",
    "\tmean_B = mean['search_count'].iloc[1]\n",
    "\n",
    "\tdiff = mean_A-mean_B\n",
    "\tif(diff>THRESHOULD):\n",
    "\t\tcnt += 1\n",
    "\n",
    "p_value = cnt/ITER\n",
    "print('p value = ',p_value)\n",
    "if(p_value < 0.01):\n",
    "\tprint('Null hypothesis rejected.')\n",
    "else:\n",
    "\tprint('The difference is caused by design difference.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to use the same dataset to do another A/B testing. We suspect that instructors are the ones who can get more useful information from the search feature, so perhaps non-instructors didn't touch the search feature because it was genuinely not relevant to them.\n",
    "\n",
    "So we decide to repeat the above analysis looking only at instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. If using the same dataset to do this analysis, do you feel like we're p-hacking? If so, what can we do with it?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Yes, it is considered as p-hacking. Because in this case, we are perfroming multiple analysis on the same dataset and we are manipulating analysis to produce statistically significant results. To solve this problem, it is to use Bonferroni correction. We record the number of all siginificance tests conducted and divid one's criterion for significance by this number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Chi-squared Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tens of different hypothesis testing methods. It's impossible to cover all of them in one week. Given that this is an important topic in statistics, I highly recommend using your free time to learn some other popular ones such as <a href=\"https://en.wikipedia.org/wiki/Chi-squared_test\">Chi-squared test</a>, <a href=\"https://en.wikipedia.org/wiki/G-test\">G-test</a>, <a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\">T-test</a>, and <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mannâ€“Whitney U test</a>.\n",
    "\n",
    "On the searchlog dataset, there are two categorical columns: `is_instructor` and `search_ui`. In Task D, your job is to first learn how a Chi-Squired test works by yourself and then use it to test whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to compute the Chi-squared stat. Note that you are **not** allowed to call an existing function (e.g., stats.chi2, chi2_contingency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chisquare value is:  0.6731740891275046\n",
      "degree of freedom is:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df  = pd.read_json('searchlog.json', lines=True)\n",
    "\n",
    "# count \n",
    "is_A = df[(df['is_instructor'] == True) & (df['search_ui'] == 'A')].count().iloc[0]\n",
    "is_B = df[(df['is_instructor'] == True) & (df['search_ui'] == 'B')].count().iloc[0]\n",
    "not_A = df[(df['is_instructor'] == False) & (df['search_ui'] == 'A')].count().iloc[0]\n",
    "not_B = df[(df['is_instructor'] == False) & (df['search_ui'] == 'B')].count().iloc[0]\n",
    "\n",
    "is_instructor = is_A + is_B\n",
    "not_instructor = not_A + not_B\n",
    "\n",
    "A = is_A + not_A\n",
    "B = is_B + not_B\n",
    "\n",
    "Sum = A+B\n",
    "\n",
    "# exp\n",
    "exp_is_A = (is_instructor * A)/Sum\n",
    "exp_is_B = (is_instructor * B)/Sum\n",
    "exp_not_A = (not_instructor * A)/Sum\n",
    "exp_not_B = (not_instructor * B)/Sum\n",
    "\n",
    "# chi-square value\n",
    "x = (is_A - exp_is_A)**2/exp_is_A + (is_B-exp_is_B)**2/exp_is_B\\\n",
    "\t+ (not_A - exp_not_A)**2/exp_not_A + (not_B-exp_not_B)**2/exp_not_B\n",
    "\n",
    "print('chisquare value is: ', x)\n",
    "print('degree of freedom is: ', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain how to use Chi-squared test to determine whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** Our hypothesis here is that $H_0$ `is_instructor` and `search_ui` are not correlated, and $H_1$ `is_instructor` and `search_ui` are correlated. The degree of freedom here is 1, and assume we use the 0.05 as the level of confidence, we get the value 3.84( by looking up in the given table of chi-square value). Our value is 0.673 which is smaller than 3.84, so we cannot reject $H_0$, that is, `is_instructor` and `search_ui` are not correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
